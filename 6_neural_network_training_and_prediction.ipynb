{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a867836",
   "metadata": {},
   "source": [
    "Bayesian Neural Network model traning and prediction data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210da263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfk = tf.keras\n",
    "tf.keras.backend.set_floatx(\"float32\")\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dadf6ec",
   "metadata": {},
   "source": [
    "Load the training databases, generated in player_match_database_creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa098fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = pd.read_excel('mid_outputs/database_entries.xlsx', index_col = 0)   \n",
    "db2 = pd.read_excel('mid_outputs/season2021/database_entries.xlsx', index_col = 0)   \n",
    "db3 = pd.read_excel('mid_outputs/season2122/database_entries.xlsx', index_col = 0)   \n",
    "db4 = pd.read_excel('mid_outputs/season2223/database_entries.xlsx', index_col = 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71fa9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.concat([db1, db2, db3, db4], ignore_index = True) \n",
    "\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d024554",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_gk1 = pd.read_excel('mid_outputs/database_entries_gk.xlsx', index_col = 0)   \n",
    "db_gk2 = pd.read_excel('mid_outputs/season2021/database_entries_gk.xlsx', index_col = 0)   \n",
    "db_gk3 = pd.read_excel('mid_outputs/season2122/database_entries_gk.xlsx', index_col = 0)   \n",
    "db_gk4 = pd.read_excel('mid_outputs/season2223/database_entries_gk.xlsx', index_col = 0)   \n",
    "\n",
    "db_gk = pd.concat([db_gk1, db_gk2, db_gk3, db_gk4], ignore_index = True) \n",
    "\n",
    "db_gk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04df0936",
   "metadata": {},
   "source": [
    "Load player stats from current season and past seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9dae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_orig = pd.read_excel('mid_outputs/players_stats.xlsx', index_col = 3)\n",
    "#players = pd.read_excel('mid_outputs/players_stats_rwk.xlsx', index_col = 3) # reworked stats to account for past season\n",
    "\n",
    "players_old = pd.read_excel('mid_outputs/season2223/players_stats.xlsx', index_col = 3)\n",
    "players_old_2 = pd.read_excel('mid_outputs/season2122/players_stats.xlsx', index_col = 3)\n",
    "players_old_3 = pd.read_excel('mid_outputs/season2021/players_stats.xlsx', index_col = 3)\n",
    "\n",
    "players = players_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397babf2",
   "metadata": {},
   "source": [
    "Load team data from current season and add an average Serie A team row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data = pd.read_excel('mid_outputs/team_data.xlsx', index_col = 0)\n",
    "\n",
    "avg_row = pd.DataFrame(index = ['Avg'], data = [team_data.mean()], columns = team_data.columns)\n",
    "avg_row['team']['Avg'] = 'Avg'\n",
    "\n",
    "team_data = pd.concat([team_data, avg_row])\n",
    "\n",
    "team_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1cd13d",
   "metadata": {},
   "source": [
    "Data processing functions copied from player_match_dataset_creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f56138",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_abs = ['r',\n",
    " 'games',\n",
    " 'games_starts',                \n",
    " 'minutes',\n",
    " 'shots_on_target_pct',\n",
    " 'goals_per_shot',\n",
    " 'goals_per_shot_on_target',\n",
    " 'passes_pct',\n",
    " #'dribble_tackles_pct',\n",
    " #'dribbles_completed_pct',\n",
    " 'aerials_won_pct',\n",
    " 'team_possession',\n",
    " 'team_goals_assists_per90',\n",
    " 'team_goals_pens_per90',\n",
    " 'team_goals_assists_pens_per90',\n",
    " 'team_xg_per90',\n",
    " 'team_gk_goals_against_per90',\n",
    " 'team_gk_save_pct',\n",
    " 'team_gk_clean_sheets_pct',\n",
    " 'team_passes_pct',\n",
    " 'team_passes_pct_medium',\n",
    " 'team_passes_pct_long',\n",
    " 'team_sca_per90',\n",
    " 'team_gca_per90',\n",
    " #'team_dribble_tackles_pct',\n",
    " 'team_aerials_won_pct',\n",
    " 'vs_team_possession',\n",
    " 'vs_team_goals_per90',\n",
    " 'vs_team_assists_per90',\n",
    " 'vs_team_xg_per90',\n",
    " 'vs_team_gk_save_pct',\n",
    " 'vs_team_gk_clean_sheets_pct',\n",
    " 'vs_team_gk_pct_passes_launched',\n",
    " 'vs_team_gk_crosses_stopped_pct',\n",
    " 'vs_team_shots_on_target_per90',\n",
    " 'vs_team_passes_pct',\n",
    " 'vs_team_passes_pct_short',\n",
    " 'vs_team_passes_pct_medium',\n",
    " 'vs_team_passes_pct_long',\n",
    " 'vs_team_sca_per90',\n",
    " 'vs_team_gca_per90',\n",
    " #'vs_team_dribble_tackles_pct',\n",
    " #'vs_team_dribbles_completed_pct',\n",
    " 'vs_team_aerials_won_pct',\n",
    " 'opp_team_possession',\n",
    " 'opp_team_goals_assists_per90',\n",
    " 'opp_team_goals_pens_per90',\n",
    " 'opp_team_goals_assists_pens_per90',\n",
    " 'opp_team_xg_per90',\n",
    " 'opp_team_gk_goals_against_per90',\n",
    " 'opp_team_gk_save_pct',\n",
    " 'opp_team_gk_clean_sheets_pct',\n",
    " 'opp_team_passes_pct',\n",
    " 'opp_team_passes_pct_medium',\n",
    " 'opp_team_passes_pct_long',\n",
    " 'opp_team_sca_per90',\n",
    " 'opp_team_gca_per90',\n",
    " #'opp_team_dribble_tackles_pct',\n",
    " 'opp_team_aerials_won_pct',\n",
    " 'opp_vs_team_possession',\n",
    " 'opp_vs_team_goals_per90',\n",
    " 'opp_vs_team_assists_per90',\n",
    " 'opp_vs_team_xg_per90',\n",
    " 'opp_vs_team_gk_save_pct',\n",
    " 'opp_vs_team_gk_clean_sheets_pct',\n",
    " 'opp_vs_team_gk_pct_passes_launched',\n",
    " 'opp_vs_team_gk_crosses_stopped_pct',\n",
    " 'opp_vs_team_shots_on_target_per90',\n",
    " 'opp_vs_team_passes_pct',\n",
    " 'opp_vs_team_passes_pct_short',\n",
    " 'opp_vs_team_passes_pct_medium',\n",
    " 'opp_vs_team_passes_pct_long',\n",
    " 'opp_vs_team_sca_per90',\n",
    " 'opp_vs_team_gca_per90',\n",
    " #'opp_vs_team_dribble_tackles_pct',\n",
    " #'opp_vs_team_dribbles_completed_pct',\n",
    " 'opp_vs_team_aerials_won_pct',\n",
    "                \n",
    " 'vote_avg',\n",
    " 'vote_std']\n",
    "\n",
    "features_rel = [\n",
    " 'goals',\n",
    " 'assists',\n",
    " 'cards_yellow',\n",
    " 'cards_red',\n",
    " 'xg',\n",
    " 'npxg',\n",
    " 'shots_on_target',\n",
    " 'passes_completed',\n",
    " 'passes_into_final_third',\n",
    " 'passes_into_penalty_area',\n",
    " 'progressive_passes',\n",
    " 'passes_live',\n",
    " 'passes_dead',\n",
    " 'through_balls',\n",
    " 'passes_switches',\n",
    " 'crosses',\n",
    " 'corner_kicks',\n",
    " #'dribble_tackles',\n",
    " #'dribbles_vs',\n",
    " #'dribbled_past',\n",
    " 'blocks',\n",
    " 'blocked_shots',\n",
    " 'blocked_passes',\n",
    " 'interceptions',\n",
    " 'clearances',\n",
    " 'errors',\n",
    " 'touches',\n",
    " 'touches_def_pen_area',\n",
    " 'touches_def_3rd',\n",
    " 'touches_mid_3rd',\n",
    " 'touches_att_3rd',\n",
    " 'touches_att_pen_area',\n",
    " 'touches_live_ball',\n",
    " #'dribbles_completed',\n",
    " #'dribbles',\n",
    " 'passes_received',\n",
    " 'miscontrols',\n",
    " 'dispossessed',\n",
    " 'fouls',\n",
    " 'fouled',\n",
    " 'aerials_won',\n",
    " 'aerials_lost',\n",
    " 'carries',\n",
    " 'progressive_carries',\n",
    " 'carries_into_final_third',\n",
    " 'carries_into_penalty_area']\n",
    "\n",
    "features_rel_gamecorr = [\n",
    "    'goals',\n",
    "    'assists',\n",
    "    'xg',\n",
    "    'npxg',\n",
    "    'cards_yellow',\n",
    "    'cards_red'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_abs_gk = [\n",
    " 'gk_games',\n",
    " 'gk_games_starts',\n",
    " 'gk_minutes',\n",
    " 'gk_goals_against_per90', \n",
    " 'gk_save_pct',\n",
    " 'gk_clean_sheets_pct',\n",
    " 'gk_psxg_net_per90',\n",
    " 'gk_passes_pct_launched',\n",
    " 'gk_pct_passes_launched',\n",
    " 'gk_passes_length_avg',\n",
    " 'gk_pct_goal_kicks_launched',\n",
    " 'gk_goal_kick_length_avg',\n",
    " 'gk_crosses_stopped_pct',\n",
    " 'gk_def_actions_outside_pen_area_per90',\n",
    " 'gk_avg_distance_def_actions',\n",
    "    \n",
    " 'team_possession',\n",
    " 'team_goals_assists_per90',\n",
    " 'team_goals_pens_per90',\n",
    " 'team_goals_assists_pens_per90',\n",
    " 'team_xg_per90',\n",
    " 'team_gk_goals_against_per90',\n",
    " 'team_gk_save_pct',\n",
    " 'team_gk_clean_sheets_pct',\n",
    " 'team_passes_pct',\n",
    " 'team_passes_pct_medium',\n",
    " 'team_passes_pct_long',\n",
    " 'team_sca_per90',\n",
    " 'team_gca_per90',\n",
    " #'team_dribble_tackles_pct',\n",
    " 'team_aerials_won_pct',\n",
    " 'vs_team_possession',\n",
    " 'vs_team_goals_per90',\n",
    " 'vs_team_assists_per90',\n",
    " 'vs_team_xg_per90',\n",
    " 'vs_team_gk_save_pct',\n",
    " 'vs_team_gk_clean_sheets_pct',\n",
    " 'vs_team_gk_pct_passes_launched',\n",
    " 'vs_team_gk_crosses_stopped_pct',\n",
    " 'vs_team_shots_on_target_per90',\n",
    " 'vs_team_passes_pct',\n",
    " 'vs_team_passes_pct_short',\n",
    " 'vs_team_passes_pct_medium',\n",
    " 'vs_team_passes_pct_long',\n",
    " 'vs_team_sca_per90',\n",
    " 'vs_team_gca_per90',\n",
    " #'vs_team_dribble_tackles_pct',\n",
    " #'vs_team_dribbles_completed_pct',\n",
    " 'vs_team_aerials_won_pct',\n",
    " 'opp_team_possession',\n",
    " 'opp_team_goals_assists_per90',\n",
    " 'opp_team_goals_pens_per90',\n",
    " 'opp_team_goals_assists_pens_per90',\n",
    " 'opp_team_xg_per90',\n",
    " 'opp_team_gk_goals_against_per90',\n",
    " 'opp_team_gk_save_pct',\n",
    " 'opp_team_gk_clean_sheets_pct',\n",
    " 'opp_team_passes_pct',\n",
    " 'opp_team_passes_pct_medium',\n",
    " 'opp_team_passes_pct_long',\n",
    " 'opp_team_sca_per90',\n",
    " 'opp_team_gca_per90',\n",
    " #'opp_team_dribble_tackles_pct',\n",
    " 'opp_team_aerials_won_pct',\n",
    " 'opp_vs_team_possession',\n",
    " 'opp_vs_team_goals_per90',\n",
    " 'opp_vs_team_assists_per90',\n",
    " 'opp_vs_team_xg_per90',\n",
    " 'opp_vs_team_gk_save_pct',\n",
    " 'opp_vs_team_gk_clean_sheets_pct',\n",
    " 'opp_vs_team_gk_pct_passes_launched',\n",
    " 'opp_vs_team_gk_crosses_stopped_pct',\n",
    " 'opp_vs_team_shots_on_target_per90',\n",
    " 'opp_vs_team_passes_pct',\n",
    " 'opp_vs_team_passes_pct_short',\n",
    " 'opp_vs_team_passes_pct_medium',\n",
    " 'opp_vs_team_passes_pct_long',\n",
    " 'opp_vs_team_sca_per90',\n",
    " 'opp_vs_team_gca_per90',\n",
    " #'opp_vs_team_dribble_tackles_pct',\n",
    " #'opp_vs_team_dribbles_completed_pct',\n",
    " 'opp_vs_team_aerials_won_pct',\n",
    "                \n",
    " 'vote_avg',\n",
    " 'vote_std']\n",
    "\n",
    "features_rel_gk = [\n",
    " 'gk_shots_on_target_against',\n",
    " 'gk_saves',\n",
    " 'gk_free_kick_goals_against',\n",
    " 'gk_corner_kick_goals_against',\n",
    " 'gk_own_goals_against',\n",
    " 'gk_psxg',\n",
    " 'gk_psnpxg_per_shot_on_target_against',\n",
    " 'gk_psxg_net',\n",
    " 'gk_passes_completed_launched',\n",
    " 'gk_passes_launched',\n",
    " 'gk_passes',\n",
    " 'gk_passes_throws',\n",
    " 'gk_goal_kicks',\n",
    " 'gk_crosses',\n",
    " 'gk_crosses_stopped',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4017b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEL_G = False\n",
    "\n",
    "features_to_del = [\n",
    "    'goals',\n",
    "    'assists',\n",
    "    'xg',\n",
    "    'npxg'\n",
    "]\n",
    "\n",
    "def player_match_data(player, pteam, oppteam, oldseason = False):\n",
    "    if(not(player in players.index)):\n",
    "        return None\n",
    "    \n",
    "    if(oldseason):\n",
    "        pdata = players_old.loc[[player]]\n",
    "    else:\n",
    "        pdata = players.loc[[player]]\n",
    "    \n",
    "    pteam_stats = team_data.loc[[pteam]].rename(index = {pteam : player})\n",
    "    \n",
    "    oppteam_stats = team_data.loc[[oppteam]].rename(index = {oppteam : player})\n",
    "    \n",
    "    oppteam_stats = oppteam_stats.rename(lambda x: 'opp_' + x, axis='columns')\n",
    "    \n",
    "    out = pd.concat([pdata, pteam_stats, oppteam_stats], axis = 1)\n",
    "    \n",
    "    return(out)\n",
    "\n",
    "def player_match_data_ext(player, pteam, oppteam, oldseason = False):\n",
    "    pdata = player_match_data(player, pteam, oppteam, oldseason = oldseason)\n",
    "    \n",
    "    if(not isinstance(pdata, pd.DataFrame)):\n",
    "        return None\n",
    "    \n",
    "    assert pdata['games'][0] > 0\n",
    "        \n",
    "    out = pd.concat([pdata[features_abs], pdata[features_rel]], axis = 1)\n",
    "    \n",
    "    out[features_rel] = out[features_rel] / max(pdata['minutes'][0], 1)\n",
    "    \n",
    "    out[features_rel_gamecorr] = out[features_rel_gamecorr] * (pdata['minutes'][0] / max(pdata['games'][0], 1) / 90)\n",
    "    \n",
    "    if(DEL_G):\n",
    "        out[features_to_del] = 0\n",
    "    \n",
    "    return out\n",
    "\n",
    "def player_match_data_ext_gk(player, pteam, oppteam, oldseason = False):\n",
    "    pdata = player_match_data(player, pteam, oppteam, oldseason = oldseason)\n",
    "    \n",
    "    if(not isinstance(pdata, pd.DataFrame)):\n",
    "        return None\n",
    "    \n",
    "    if(pdata['gk_games'][0] <= 0):\n",
    "        return None\n",
    "    \n",
    "    out = pd.concat([pdata[features_abs_gk], pdata[features_rel_gk]], axis = 1)\n",
    "    \n",
    "    out[features_rel_gk] = out[features_rel_gk] / max(pdata['minutes'][0], 1)\n",
    "\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6700ec",
   "metadata": {},
   "source": [
    "Load data from previous seasons in other leagues, for new players (rookies) in Serie A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rookies_data = pd.read_excel('rookies_stats/out_data/rookies_stats.xlsx', index_col = 1)\n",
    "\n",
    "rookies_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fef3ae",
   "metadata": {},
   "source": [
    "Players stats rework:\n",
    "the current season stats are averaged (according to a calculated weight) with the past season data.\n",
    "In case a player doesn't have past season data, a config file (affine_players) can be used to load the data from an affine player (past season), e.g. Doig affine to Lazovic.\n",
    "In case, after this process, the player doesn't result in having a minimum amount of games, its stats are averaged with the average Serie A (defensive) player stat, depending on the games remaining to reach the minimum amount. This allows to use players who still haven't played a single game.\n",
    "\n",
    "These modified stats are used only for prediction, not for model traning.\n",
    "\n",
    "WEIGHT_0 = weight given to the current season in respect to the previous; if the player has a low amount of games this season, the weight is lowered\n",
    "min_games = minimum games so that the players stats are not averaged with the avg Serie A player stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8707b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(players.columns.shape[0]):\n",
    "#    print(str(i) + ' - ' + players.columns[i])\n",
    "\n",
    "cols_toadapt = players.columns[9:]\n",
    "cols_toadapt_rookies = rookies_data.columns.intersection(cols_toadapt)\n",
    "\n",
    "players = players_orig.copy()\n",
    "\n",
    "min_games = 6\n",
    "\n",
    "current_season_games = max(10, max(players_orig['games']))\n",
    "\n",
    "# weight_0 as function of current_season_games --> 1 as match day reachs 30 ? \n",
    "WEIGHT_0_same_team = (1 - (1 - 0.7) * (30 - current_season_games) / (38 - 12)) # 0.7\n",
    "WEIGHT_0_different_team = (1 - (1 - 0.75) * (30 - current_season_games) / (38 - 12)) # 0.75\n",
    "WEIGHT_mul_gk = 2\n",
    "\n",
    "rcsv = pd.read_csv('config/affine_players.txt')   \n",
    "affine_players = pd.DataFrame(rcsv)\n",
    "affine_players = affine_players.set_index('player')\n",
    "\n",
    "\n",
    "def calc_weight(games_curr, games_old, same_team = 1, maxgames = current_season_games):\n",
    "    if(same_team):\n",
    "        weight_0 = WEIGHT_0_same_team\n",
    "    else:\n",
    "        weight_0 = WEIGHT_0_different_team\n",
    "\n",
    "    weight = weight_0 * (games_curr / maxgames) / (max(games_old, 1) / 38)\n",
    "    weight = min(weight, 1)\n",
    "\n",
    "    return abs(weight)\n",
    "\n",
    "print(' ')\n",
    "print('Averaging players stats with past seasons:')\n",
    "\n",
    "\n",
    "for i in range(players.shape[0]):\n",
    "    p = players.index[i]\n",
    "    \n",
    "\n",
    "    if(p in players_old.index or p in affine_players.index):\n",
    "        p_ = p\n",
    "        affine = 0\n",
    "        \n",
    "        if(p in affine_players.index):\n",
    "            affine = 1\n",
    "            p_ = affine_players.loc[p]['alike']\n",
    "            \n",
    "            print(p + ' affine to ' + p_)\n",
    "        \n",
    "        if(players.loc[p]['r'] == 'P'):\n",
    "            weight = calc_weight(players.loc[p]['gk_games'], players_old.loc[p_]['gk_games'], affine == 1 or players.loc[p]['team'] == players_old.loc[p]['team'])\n",
    "            weight *= WEIGHT_mul_gk\n",
    "            weight = min(weight, 1)\n",
    "        else:\n",
    "            weight = calc_weight(players.loc[p]['games'], players_old.loc[p_]['games'], affine == 1 or players.loc[p]['team'] == players_old.loc[p]['team'])\n",
    "\n",
    "        players.at[p, cols_toadapt] = (players.loc[p][cols_toadapt] * weight + (1-weight) * players_old.loc[p_][cols_toadapt])\n",
    "        \n",
    "        print(p + ' ' + str(weight))     \n",
    "    elif(p in rookies_data.index):\n",
    "        p_ = p\n",
    "        weight = calc_weight(players.loc[p]['games'], rookies_data.loc[p_]['games'], False)\n",
    "        players.at[p, cols_toadapt_rookies] = (players.loc[p][cols_toadapt_rookies] * weight + (1-weight) * rookies_data.loc[p_][cols_toadapt_rookies])\n",
    "        \n",
    "        print(p + ' ' + str(weight) + ' (rookie)')     \n",
    "\n",
    "    \n",
    "    # to handle players like Scamacca, who only played 2 seasons ago; only outfield players\n",
    "    if(players.loc[p]['r'] != 'P' and players.loc[p]['games'] < min_games and p in players_old_2.index):    \n",
    "        weight = calc_weight(players.loc[p]['games'], players_old_2.loc[p]['games'], players.loc[p]['team'] == players_old_2.loc[p]['team'])\n",
    "        \n",
    "        players.at[p, cols_toadapt] = (players.loc[p][cols_toadapt] * weight + (1-weight) * players_old_2.loc[p][cols_toadapt])\n",
    "        \n",
    "        print(p + ' ' + str(weight) + ' (two seasons ago)')\n",
    "    \n",
    "    \n",
    "# handle players with low quantitites of games\n",
    "\n",
    "print('Players with low quantity of games:')\n",
    "\n",
    "def calc_weight_low(current_games, min_games = min_games):\n",
    "    weight = 1 - (min_games - current_games)/min_games\n",
    "    \n",
    "    weight = min(weight, 1)\n",
    "\n",
    "    return abs(weight)\n",
    "\n",
    "#mean_players_stats = players_orig[players_orig['games'] >= min_games][cols_toadapt].mean()\n",
    "\n",
    "\n",
    "# mean players stats based on old season\n",
    "\n",
    "mean_players_stats = players_orig.loc[players_orig.index[0]][cols_toadapt] * 0\n",
    "count = 0\n",
    "\n",
    "for i in range(players_old.shape[0]):\n",
    "    if(players_old['games'][i] >= min_games and (players_old['r'][i] == 'D')): # counting only defenders, to add a penalty\n",
    "        mean_players_stats += players_old.loc[players_old.index[i]][cols_toadapt]\n",
    "        count = count + 1\n",
    "        \n",
    "mean_players_stats /= count\n",
    "\n",
    "for i in range(players.shape[0]):\n",
    "    p = players.index[i]\n",
    "    \n",
    "    if(players.loc[p]['games'] < min_games and players.loc[p]['r'] != 'P'):\n",
    "        weight = calc_weight_low(players.loc[p]['games'])\n",
    "        \n",
    "        players.at[p, cols_toadapt] = players.loc[p][cols_toadapt] * weight + (1-weight) * mean_players_stats\n",
    "        \n",
    "        print(p + ' ' + str(weight))\n",
    "        \n",
    "        \n",
    "players_out = players.copy()\n",
    "players_out = players_out.set_index(players_out.columns[0])\n",
    "players_out.insert(2, 'name', players_out.index)\n",
    "players_out.to_excel('mid_outputs/players_stats_rwk.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c28b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "players.columns[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29102e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(db.columns.shape[0]):\n",
    "    print(str(i) + \" - \" + str(db.columns[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089690d6",
   "metadata": {},
   "source": [
    "Elaborate databases data to have X and y for training, and split into a train test and a validation test.\n",
    "\n",
    "For outfield players: X -> y = [vote, fantavote]\n",
    "\n",
    "For goalkeepers: X -> y = [vote, fantavote, clean sheet probability]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19304f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "npdb = np.array(db)\n",
    "\n",
    "y = npdb[:, [5,9]] # vote, fantavote\n",
    "\n",
    "#y[:, 1] = y[:, 1] - y[:, 0] # target = difference between fantavote and vote\n",
    "\n",
    "f_start = 14\n",
    "\n",
    "X = npdb[:, f_start:]\n",
    "\n",
    "if(DEL_G): \n",
    "    del_g_idx = [\n",
    "        list(db.columns).index('goals.1') - f_start,\n",
    "        list(db.columns).index('assists.1') - f_start,\n",
    "        list(db.columns).index('xg') - f_start,\n",
    "        list(db.columns).index('npxg') - f_start,\n",
    "        list(db.columns).index('shots_on_target') - f_start]\n",
    "    \n",
    "    X[:, del_g_idx] = 0\n",
    "\n",
    "\n",
    "# add role and home factor\n",
    "toadd = np.zeros((X.shape[0], 4))\n",
    "toadd[:, 0] = npdb[:, 4] # home\n",
    "\n",
    "toadd[:, 1] = npdb[:, 10] == 'D'\n",
    "toadd[:, 2] = npdb[:, 10] == 'C'\n",
    "toadd[:, 3] = npdb[:, 10] == 'A'\n",
    "\n",
    "X = np.concatenate((X, toadd), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X_train_, X_test_, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)\n",
    "\n",
    "X_train = scaler.transform(X_train_)\n",
    "X_test = scaler.transform(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b1fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(db_gk.columns.shape[0]):\n",
    "    print(str(i) + \" - \" + str(db_gk.columns[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7cf079",
   "metadata": {},
   "outputs": [],
   "source": [
    "npdb_gk= np.array(db_gk)\n",
    "\n",
    "y_gk = npdb_gk[:, [5,9,6]] # vote, fantavote, goals == 0 (clean sheet)\n",
    "y_gk[:, 2] = (y_gk[:, 2] == 0) * 1\n",
    "\n",
    "f_start_gk = 13\n",
    "\n",
    "X_gk = npdb_gk[:, f_start_gk:]\n",
    "\n",
    "# add home factor\n",
    "toadd_gk = np.zeros((X_gk.shape[0], 1))\n",
    "toadd_gk[:, 0] = npdb_gk[:, 4] # home\n",
    "\n",
    "X_gk = np.concatenate((X_gk, toadd_gk), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_gk = StandardScaler()\n",
    "scaler_gk.fit(X_gk)\n",
    "\n",
    "X_gk_train_, X_gk_test_, y_gk_train, y_gk_test = train_test_split(X_gk, y_gk, test_size = 0.2, random_state = 18)\n",
    "\n",
    "X_gk_train = scaler_gk.transform(X_gk_train_)\n",
    "X_gk_test = scaler_gk.transform(X_gk_test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd27493",
   "metadata": {},
   "source": [
    "MLP Regressor , to see performance of a simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04564bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = MLPRegressor(max_iter = 400000, solver = 'lbfgs', hidden_layer_sizes = (8, 8), alpha = 500, verbose = True)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_train_predict = regr.predict(X_train)\n",
    "\n",
    "plt.plot([0, 20], [0, 20])\n",
    "\n",
    "plt.scatter(y_train[:, 0], y_train_predict[:, 0], color = 'orange', edgecolors = 'black', s = 20)\n",
    "plt.scatter(y_train[:, 1], y_train_predict[:, 1], color = 'green', edgecolors = 'black', s = 20)\n",
    "\n",
    "print(r2_score(y_train[:, 0], y_train_predict[:, 0]))\n",
    "print(r2_score(y_train[:, 1], y_train_predict[:, 1]))\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "y_test_predict = regr.predict(X_test)\n",
    "\n",
    "plt.plot([0, 20], [0, 20])\n",
    "\n",
    "plt.scatter(y_test[:, 0], y_test_predict[:, 0], color = 'orange', edgecolors = 'black', s = 20)\n",
    "plt.scatter(y_test[:, 1], y_test_predict[:, 1], color = 'green', edgecolors = 'black', s = 20)\n",
    "\n",
    "print(r2_score(y_test[:, 0], y_test_predict[:, 0]))\n",
    "print(r2_score(y_test[:, 1], y_test_predict[:, 1]))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9513b25",
   "metadata": {},
   "source": [
    "Train neural network for outfield players.\n",
    "\n",
    "The outputs of the NN are probability distribution of SinhArcsinh type (a skewed distribution, which is a generalization of Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aad9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_of = True# load scaler and model weights for outfield player predictor\n",
    "refit_model_of = True\n",
    "\n",
    "if(load_model_of):\n",
    "    scaler = pickle.load(open('saves/scaler.pkl', 'rb'))\n",
    "    \n",
    "    X_train = scaler.transform(X_train_)\n",
    "    X_test = scaler.transform(X_test_)\n",
    "\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "X_len = X_train.shape[1]\n",
    "y_len = y_train.shape[1]\n",
    "\n",
    "\n",
    "#tailweight_param = 1.1\n",
    "\n",
    "tailweight_min = 0.5\n",
    "tailweight_range = 1.2\n",
    "\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 10)\n",
    "neg_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)\n",
    "\n",
    "\n",
    "inputs = tfk.layers.Input(shape=(X_len,), name=\"input\")\n",
    "x = tfk.layers.Dropout(0.2)(inputs)\n",
    "x = tfk.layers.Dense(16, activation=\"relu\") (x)\n",
    "x = tfk.layers.Dropout(0.2)(x)\n",
    "x = tfk.layers.Dense(16, activation=\"relu\") (x)\n",
    "\n",
    "\n",
    "prob_dist_params = 4\n",
    "\n",
    "def prob_dist(t): \n",
    "    return tfp.distributions.SinhArcsinh(loc=t[..., 0], scale=1e-3 + tf.math.softplus(t[..., 1]), skewness = t[..., 2], \n",
    "                                        tailweight = tailweight_min + tailweight_range * tf.math.sigmoid(t[..., 3]),\n",
    "                                        allow_nan_stats = False)\n",
    "\n",
    "x1 = tfk.layers.Dense(8, activation=\"sigmoid\")(x)\n",
    "x1 = tfk.layers.Dense(prob_dist_params, activation=\"linear\")(x1)\n",
    "out_1 = tfp.layers.DistributionLambda(prob_dist)(x1)\n",
    "\n",
    "x2 = tfk.layers.Dense(8, activation=\"sigmoid\")(x)\n",
    "x2 = tfk.layers.Dense(prob_dist_params, activation=\"linear\")(x2)\n",
    "out_2 = tfp.layers.DistributionLambda(prob_dist)(x2)\n",
    "\n",
    "\n",
    "modelb = tf.keras.Model(inputs, [out_1, out_2])\n",
    "\n",
    "modelb.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate = 0.001), \n",
    "              loss=neg_log_likelihood)\n",
    "\n",
    "if(load_model_of):\n",
    "    modelb.load_weights('saves/modelb')\n",
    "    \n",
    "if( (not load_model_of) or refit_model_of):\n",
    "    modelb.fit(X_train.astype('float32'), [y_train[:, 0].astype('float32'), y_train[:, 1].astype('float32')], \n",
    "              validation_data = (X_test.astype('float32'), [y_test[:, 0].astype('float32'), y_test[:, 1].astype('float32')]),\n",
    "              batch_size = batch_size, shuffle = True, epochs=n_epochs, verbose=True, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2bf9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_predict(X, iterations = 100):\n",
    "    y = np.zeros((2, X.shape[0]))\n",
    "    \n",
    "    dist = modelb(X)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        y[0, :] += dist[0].sample()\n",
    "        y[1, :] += dist[1].sample()\n",
    "        \n",
    "    return y.transpose() / iterations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2674211",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = sample_predict(X_train)\n",
    "\n",
    "plt.plot([0, 20], [0, 20])\n",
    "\n",
    "plt.scatter(y_train[:, 0], y_train_predict[:, 0], color = 'orange', edgecolors = 'black', s = 20)\n",
    "plt.scatter(y_train[:, 1], y_train_predict[:, 1], color = 'green', edgecolors = 'black', s = 20)\n",
    "\n",
    "print(r2_score(y_train[:, 0], y_train_predict[:, 0]))\n",
    "print(r2_score(y_train[:, 1], y_train_predict[:, 1]))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "y_test_predict = sample_predict(X_test)\n",
    "\n",
    "plt.plot([0, 20], [0, 20])\n",
    "\n",
    "plt.scatter(y_test[:, 0], y_test_predict[:, 0], color = 'orange', edgecolors = 'black', s = 20)\n",
    "plt.scatter(y_test[:, 1], y_test_predict[:, 1], color = 'green', edgecolors = 'black', s = 20)\n",
    "\n",
    "print(r2_score(y_test[:, 0], y_test_predict[:, 0]))\n",
    "print(r2_score(y_test[:, 1], y_test_predict[:, 1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f574ffdb",
   "metadata": {},
   "source": [
    "Train neural network for goalkeepers.\n",
    "\n",
    "For clean sheet probability prediction, a Bernoulli distribution is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_gk = True# load scaler and model weights for goalkeeper player predictor\n",
    "refit_model_gk = True\n",
    "\n",
    "if(load_model_gk):\n",
    "    scaler_gk = pickle.load(open('saves/scaler_gk.pkl', 'rb'))\n",
    "    \n",
    "    X_gk_train = scaler_gk.transform(X_gk_train_)\n",
    "    X_gk_test = scaler_gk.transform(X_gk_test_)\n",
    "    \n",
    "    \n",
    "n_epochs = 2500\n",
    "\n",
    "n_samples = X_gk_train.shape[0]\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "X_gk_len = X_gk_train.shape[1]\n",
    "y_gk_len = y_gk_train.shape[1]\n",
    "\n",
    "\n",
    "#tailweight_param = 1.1\n",
    "\n",
    "tailweight_min = 0.5\n",
    "tailweight_range = 0.8\n",
    "\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 50)\n",
    "neg_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)\n",
    "\n",
    "\n",
    "inputs = tfk.layers.Input(shape=(X_gk_len,), name=\"input\")\n",
    "x = tfk.layers.Dense(16, activation=\"relu\") (inputs)\n",
    "x = tfk.layers.Dropout(0.3)(x)\n",
    "x = tfk.layers.Dense(16, activation=\"relu\") (x)\n",
    "\n",
    "\n",
    "prob_dist_params = 4\n",
    "\n",
    "def prob_dist(t): \n",
    "    return tfp.distributions.SinhArcsinh(loc=t[..., 0], scale=1e-3 + tf.math.softplus(t[..., 1]), skewness = t[..., 2], \n",
    "                                        tailweight = tailweight_min + tailweight_range * tf.math.sigmoid(t[..., 3]),\n",
    "                                        allow_nan_stats = False)\n",
    "\n",
    "x1 = tfk.layers.Dense(16, activation=\"sigmoid\")(x)\n",
    "x1 = tfk.layers.Dropout(0.2)(x1)\n",
    "x1 = tfk.layers.Dense(prob_dist_params, activation=\"linear\")(x1)\n",
    "out_1 = tfp.layers.DistributionLambda(prob_dist)(x1)\n",
    "\n",
    "x2 = tfk.layers.Dense(16, activation=\"sigmoid\")(x)\n",
    "\n",
    "x2 = tfk.layers.Dense(prob_dist_params, activation=\"linear\")(x2)\n",
    "out_2 = tfp.layers.DistributionLambda(prob_dist)(x2)\n",
    "\n",
    "x3 = tfk.layers.Dense(8, activation=\"sigmoid\")(x)\n",
    "x3 = tfk.layers.Dropout(0.2)(x3)\n",
    "x3 = tfk.layers.Dense(1, activation=\"sigmoid\")(x3)\n",
    "out_3 = tfp.layers.DistributionLambda(lambda t: tfp.distributions.Bernoulli(probs = t[..., 0]))(x3)\n",
    "\n",
    "modelb_gk = tf.keras.Model(inputs, [out_1, out_2, out_3])\n",
    "\n",
    "modelb_gk.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate = 0.001), \n",
    "              loss=neg_log_likelihood)\n",
    "\n",
    "if(load_model_gk):\n",
    "    modelb_gk.load_weights('saves/modelb_gk')\n",
    "\n",
    "if( (not load_model_gk) or refit_model_gk):    \n",
    "    modelb_gk.fit(X_gk_train.astype('float32'), [y_gk_train[:, 0].astype('float32'), y_gk_train[:, 1].astype('float32'), y_gk_train[:, 2].astype('int')], \n",
    "              validation_data = (X_gk_test.astype('float32'), [y_gk_test[:, 0].astype('float32'), y_gk_test[:, 1].astype('float32'), y_gk_test[:, 2].astype('int')]),\n",
    "              batch_size = batch_size, shuffle = True, epochs=n_epochs, verbose=True, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a9bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_predict_gk(X, iterations = 100):\n",
    "    y = np.zeros((3, X.shape[0]))\n",
    "    \n",
    "    dist = modelb_gk(X)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        y[0, :] += dist[0].sample()\n",
    "        y[1, :] += dist[1].sample()\n",
    "        y[2, :] += dist[2].sample()\n",
    "        \n",
    "    return y.transpose() / iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41cf448",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gk_train_predict = sample_predict_gk(X_gk_train)\n",
    "\n",
    "plt.plot([0, 20], [0, 20])\n",
    "\n",
    "plt.scatter(y_gk_train[:, 0], y_gk_train_predict[:, 0], color = 'orange', edgecolors = 'black', s = 20)\n",
    "plt.scatter(y_gk_train[:, 1], y_gk_train_predict[:, 1], color = 'green', edgecolors = 'black', s = 20)\n",
    "\n",
    "print(r2_score(y_gk_train[:, 0], y_gk_train_predict[:, 0]))\n",
    "print(r2_score(y_gk_train[:, 1], y_gk_train_predict[:, 1]))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "y_gk_test_predict = sample_predict_gk(X_gk_test)\n",
    "\n",
    "plt.plot([0, 20], [0, 20])\n",
    "\n",
    "plt.scatter(y_gk_test[:, 0], y_gk_test_predict[:, 0], color = 'orange', edgecolors = 'black', s = 20)\n",
    "plt.scatter(y_gk_test[:, 1], y_gk_test_predict[:, 1], color = 'green', edgecolors = 'black', s = 20)\n",
    "\n",
    "print(r2_score(y_gk_test[:, 0], y_gk_test_predict[:, 0]))\n",
    "print(r2_score(y_gk_test[:, 1], y_gk_test_predict[:, 1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91869883",
   "metadata": {},
   "source": [
    "Use the following codes to save the scalers and the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_of = True\n",
    "save_model_gk = True\n",
    "\n",
    "if(save_model_of):\n",
    "    pickle.dump(scaler, open('saves/scaler.pkl', 'wb'))\n",
    "    modelb.save_weights('saves/modelb')\n",
    "    \n",
    "if(save_model_gk):\n",
    "    pickle.dump(scaler_gk, open('saves/scaler_gk.pkl', 'wb'))\n",
    "    modelb_gk.save_weights('saves/modelb_gk')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32635a0e",
   "metadata": {},
   "source": [
    "Generalized prediction function for a player (playing for team against opp_team, at home or not)\n",
    "\n",
    "Estimate prediction mean and sigma (using a custom definitions).\n",
    "\n",
    "Generate a plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf433f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_predict_NNb(player, team, opp_team, home = 1, plot = 0, log = 0, oldseason = False):\n",
    "    if(players['r'][player] == 'P'):\n",
    "        ptest = player_match_data_ext_gk(player, team, opp_team, oldseason = oldseason)\n",
    "\n",
    "        x_ptest = np.array(ptest)[:, 3:]\n",
    "        r = np.array(ptest)[0, 0]\n",
    "\n",
    "        # add home and role\n",
    "        xadd = np.zeros((1, 1))\n",
    "        xadd[0, 0] = home\n",
    "\n",
    "        x_ptest = np.concatenate((x_ptest, xadd), axis = 1)\n",
    "\n",
    "        x_scaled = scaler_gk.transform(x_ptest)\n",
    "\n",
    "        dist = modelb_gk(x_scaled)\n",
    "        \n",
    "        clean_shoot_prob = dist[2].probs.numpy()[0]\n",
    "    else:\n",
    "        ptest = player_match_data_ext(player, team, opp_team, oldseason = oldseason)\n",
    "\n",
    "        x_ptest = np.array(ptest)[:, 4:]\n",
    "        r = np.array(ptest)[0, 0]\n",
    "\n",
    "        # add home and role\n",
    "        xadd = np.zeros((1, 4))\n",
    "        xadd[0, 0] = home\n",
    "        xadd[0, 1] = r == 'D'\n",
    "        xadd[0, 2] = r == 'C'\n",
    "        xadd[0, 3] = r == 'A'\n",
    "\n",
    "        x_ptest = np.concatenate((x_ptest, xadd), axis = 1)\n",
    "\n",
    "        x_scaled = scaler.transform(x_ptest)\n",
    "\n",
    "        dist = modelb(x_scaled)\n",
    "    \n",
    "    \n",
    "    x = np.arange(0, 40, 0.002)\n",
    "\n",
    "    px1 = dist[0].prob(x);\n",
    "    px2 = dist[1].prob(x);\n",
    "\n",
    "    \n",
    "    #sample1 = dist[0].sample(10000)\n",
    "    #sample2 = dist[1].sample(10000)\n",
    "    \n",
    "    m1 = np.average(x, weights = px1)\n",
    "    m2 = np.average(x, weights = px2)\n",
    "    \n",
    "    #m1 = np.mean(sample1)\n",
    "    #m2 = np.mean(sample2)\n",
    "    \n",
    "    #s1 = np.std(sample1)\n",
    "    #s2 = np.std(sample2)\n",
    "      \n",
    "    # not standard deviation, but expected range extimated by quantile \n",
    "    \n",
    "    if(players['r'][player] == 'P'):\n",
    "        s1 = ( dist[0].quantile(0.9545) - m1 ) / 2\n",
    "        s2 = -( dist[1].quantile(1 - 0.9) - m2 ) / 2\n",
    "    else:\n",
    "        s1 = ( dist[0].quantile(0.9545) - m1 ) / 2\n",
    "        s2 = ( dist[1].quantile(0.9) - m2 ) / 2\n",
    "    \n",
    "\n",
    "    \n",
    "    #y_pred_m = np.array([dist[0].loc, dist[1].loc]).flatten()\n",
    "    y_pred_m = np.array([m1, m2]).flatten()\n",
    "    #y_pred_s = np.array([dist[0].scale, dist[1].scale]).flatten()\n",
    "    y_pred_s = np.array([s1, s2]).flatten()\n",
    "    \n",
    "    clean_sheet_text = ''\n",
    "    if(players['r'][player] == 'P'):\n",
    "        clean_sheet_text = ' (' + \"{:.1f}\".format(clean_shoot_prob*100) + '% cs)'\n",
    "            \n",
    "    if(plot):\n",
    "        ax = plt.gca()\n",
    "        \n",
    "        plt.plot(x, px1, \n",
    "                 label = 'MV ' + \"{:.2f}\".format(y_pred_m[0]) + ' ± ' + \"{:.2f}\".format(2 * y_pred_s[0]),\n",
    "                color = 'b')\n",
    "        plt.plot(x, px2, \n",
    "                 label = 'FV ' + \"{:.2f}\".format(y_pred_m[1]) + ' + ' + \"{:.2f}\".format(2 * y_pred_s[1]) + clean_sheet_text,\n",
    "                color = 'g')\n",
    "        \n",
    "        plt.fill_between(x, px1, color = 'lightblue')\n",
    "        plt.fill_between(x, px2, color = 'lightgreen')\n",
    "        \n",
    "        plt.legend()\n",
    "        \n",
    "        plt.vlines(x = y_pred_m[0], color = 'b', ymin = 0, ymax = 3, linestyle = 'dashed')\n",
    "        plt.vlines(x = y_pred_m[1], color = 'g', ymin = 0, ymax = 3, linestyle = 'dashed')\n",
    "        \n",
    "        plt.title(player + ' (' + team + ' vs ' + opp_team + ')')\n",
    "        \n",
    "        plt.xlim([0, 15])\n",
    "        \n",
    "        if(players['r'][player] == 'P'):            \n",
    "            plt.ylim([0, 2.5])\n",
    "        else:\n",
    "            plt.ylim([0, 1.5])\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    if(log):\n",
    "        print(player + ': ' + \n",
    "         'MV ' + \"{:.2f}\".format(y_pred_m[0]) + ' ± ' + \"{:.2f}\".format(2 * y_pred_s[0]) +\n",
    "         '; FV ' + \"{:.2f}\".format(y_pred_m[1]) + ' + ' + \"{:.2f}\".format(2 * y_pred_s[1]) + clean_sheet_text);\n",
    "    return [y_pred_m, y_pred_s, dist]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98817aa0",
   "metadata": {},
   "source": [
    "Load Serie A calendar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31bad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = np.array(pd.read_excel('fantacalcio/seriea_calendar.xlsx', header = None))\n",
    "\n",
    "cal_df = pd.DataFrame(columns = ['matchday', 'team1', 'team2'])\n",
    "\n",
    "matchday = 0\n",
    "\n",
    "for i in range(cal.shape[0]):\n",
    "    if(cal[i, 0][0].isnumeric()):\n",
    "        matchday = matchday + 1\n",
    "        continue\n",
    "    \n",
    "    teams = cal[i, 0].split('-')\n",
    "    \n",
    "    frame = pd.DataFrame([[matchday, teams[0], teams[1]]], columns = cal_df.columns)\n",
    "\n",
    "    cal_df = pd.concat([cal_df, frame], ignore_index = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cal_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62872819",
   "metadata": {},
   "source": [
    "Function for generating a prediction for a player, taking match data from a given matchday, according to Serie A calendar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58ba41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlayerMatch(player, match = 0):\n",
    "    team = players.loc[player]['team']\n",
    "    \n",
    "    if(match == 0):\n",
    "        oppteam = 'Avg'\n",
    "        home = 1\n",
    "    else:\n",
    "        for i in range (cal_df.shape[0]):\n",
    "            if(cal_df['matchday'][i] == match):\n",
    "                if(cal_df['team1'][i] == team):\n",
    "                    home = 1\n",
    "                    oppteam = cal_df['team2'][i]\n",
    "                elif(cal_df['team2'][i] == team):\n",
    "                    home = 0\n",
    "                    oppteam = cal_df['team1'][i]\n",
    "                \n",
    "    return [player, team, oppteam, home]\n",
    "\n",
    "def predict_player(player, match = 0, plot = 0, log = 0, oldseason = False):\n",
    "    [player, team, oppteam, home] = PlayerMatch(player, match)\n",
    "    return vote_predict_NNb(player, team, oppteam, home = home, plot = plot, log = log, oldseason = oldseason)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b63a98",
   "metadata": {},
   "source": [
    "Load current matchday playing probabilities for Serie A players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79792b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "probables = pd.read_excel('mid_outputs/match_probable_players.xlsx', index_col = 0)   \n",
    "\n",
    "probables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4751014",
   "metadata": {},
   "source": [
    "Generate prediction data for each Serie A player for the current matchday.\n",
    "\n",
    "Output to excel file, using a template made for data elaboration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63c2b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matchday_out = 7\n",
    "\n",
    "output = pd.DataFrame(columns = ['player', 'role', 'team', 'oppteam', 'home', 'starter', 'vote%', 'MV', 'MV std', 'FV', 'FV std', 'MV loc', 'MV scale', 'MV skewness', 'MV tailweight', 'FV loc', 'FV scale', 'FV skewness', 'FV tailweight', 'Clean Sheet %'])\n",
    "\n",
    "for i in range(players.shape[0]):\n",
    "    try:\n",
    "        [player, team, oppteam, home] = PlayerMatch(players.index[i], matchday_out)\n",
    "        \n",
    "        [mean, std, dist] = vote_predict_NNb(player, team, oppteam, home = home, log = 1)\n",
    "        \n",
    "        role = players['r'][player] \n",
    "        \n",
    "        starter = 0\n",
    "        voteperc = 0\n",
    "        \n",
    "        cs = 0\n",
    "        if(role == 'P'):\n",
    "            cs = dist[2].probs.numpy()[0] * 100\n",
    "        \n",
    "        if(player in probables.index):\n",
    "            starter = probables['starter'][player]\n",
    "            voteperc = probables['percentage'][player]\n",
    "        \n",
    "        row = [player, role, team, oppteam, home, \n",
    "               starter, voteperc, \n",
    "               mean[0], std[0], \n",
    "               mean[1], std[1], \n",
    "               dist[0].loc.numpy()[0], dist[0].scale.numpy()[0], \n",
    "               dist[0].skewness.numpy()[0], dist[0].tailweight.numpy()[0], \n",
    "               dist[1].loc.numpy()[0], dist[1].scale.numpy()[0], \n",
    "               dist[1].skewness.numpy()[0], dist[1].tailweight.numpy()[0],\n",
    "               cs]\n",
    "        \n",
    "        row_df = pd.DataFrame(data = [row], columns = output.columns)\n",
    "        \n",
    "        output = pd.concat([output, row_df])\n",
    "        \n",
    "    except:\n",
    "        print(players.index[i] + ' no data')\n",
    "\n",
    "output = output.set_index('player')\n",
    "\n",
    "output = output.sort_values(['team', 'role', 'FV'], ascending = [True, False, False])\n",
    "#output.to_excel('outputs/pred_matchday_' + str(matchday_out) + '.xlsx')\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6befd611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "template_file = 'outputs/pred_matchday_base.xlsx'\n",
    "dest_file = 'outputs/pred_matchday_' + str(matchday_out) + '.xlsx'\n",
    "\n",
    "shutil.copyfile(template_file, dest_file)\n",
    "\n",
    "with pd.ExcelWriter(dest_file, mode = 'a', engine=\"openpyxl\", if_sheet_exists = 'replace') as writer:  \n",
    "    output.to_excel(writer, sheet_name='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed7a7ac",
   "metadata": {},
   "source": [
    "Predict average Serie A performance for each player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b637a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "gk_starters = ['Maignan', 'Ochoa', 'Silvestri', 'Consigli', 'Provedel', 'Di Gregorio', 'Meret', 'Milinkovic-Savic V.',\n",
    "              'Terracciano', 'Sommer', 'Szczesny', 'Skorupski', 'Berisha', 'Musso', 'Radunovic', 'Rui Patricio',\n",
    "              'Montipo\\'', 'Falcone', 'Martinez Jo.', 'Turati']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d73507",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(columns = ['player', 'role', 'team', 'oppteam', 'home', 'starter', 'vote%', 'MV', 'MV std', 'FV', 'FV std', 'MV loc', 'MV scale', 'MV skewness', 'MV tailweight', 'FV loc', 'FV scale', 'FV skewness', 'FV tailweight', 'Clean Sheet %'])\n",
    "\n",
    "tot_matches = 2 # home and not home\n",
    "\n",
    "current_season_games = max(players_orig['games'])\n",
    "\n",
    "for i in range(players.shape[0]):\n",
    "    try:\n",
    "        home = 0\n",
    "\n",
    "        for k in range(tot_matches):\n",
    "            #matchday_out = k + 1\n",
    "            #[player, team, oppteam, home] = PlayerMatch(players.index[i], matchday_out)\n",
    "\n",
    "            player = players.index[i]\n",
    "            team = players['team'][i]\n",
    "            oppteam = 'Avg'\n",
    "            home = not home\n",
    "\n",
    "            [mean, std, dist] = vote_predict_NNb(player, team, oppteam, home = home)\n",
    "\n",
    "            role = players['r'][player] \n",
    "\n",
    "            starter = 0\n",
    "            voteperc = 0\n",
    "\n",
    "            games = max( players_orig['games'][i], players_orig['gk_games'][i] )\n",
    "            mins = max( players_orig['minutes'][i], players_orig['gk_minutes'][i] )\n",
    "\n",
    "            cs = 0\n",
    "            if(role == 'P'):\n",
    "                cs = dist[2].probs.numpy()[0] * 100\n",
    "\n",
    "                starter = int( player in gk_starters )\n",
    "                if(starter):\n",
    "                    voteperc = 100\n",
    "                else:\n",
    "                    voteperc = 0\n",
    "            else:\n",
    "                starter = int ( 1 * (games >= current_season_games * 2/3 and mins / games >= 45 ) )\n",
    "                voteperc = int( min( 1, games / current_season_games ) * 100)     \n",
    "\n",
    "            if(k == 0):\n",
    "                row = [player, role, team, 'Avg', 1, starter, voteperc]\n",
    "\n",
    "            numrow_ = [mean[0], std[0], \n",
    "                   mean[1], std[1], \n",
    "                   dist[0].loc.numpy()[0], dist[0].scale.numpy()[0], \n",
    "                   dist[0].skewness.numpy()[0], dist[0].tailweight.numpy()[0], \n",
    "                   dist[1].loc.numpy()[0], dist[1].scale.numpy()[0], \n",
    "                   dist[1].skewness.numpy()[0], dist[1].tailweight.numpy()[0],\n",
    "                   cs]            \n",
    "\n",
    "            if(k == 0):\n",
    "                numrow = numrow_\n",
    "            else:\n",
    "                for j in range(len(numrow)):\n",
    "                    numrow[j] += numrow_[j]\n",
    "\n",
    "        for j in range(len(numrow)):\n",
    "            numrow[j] /= tot_matches\n",
    "\n",
    "        print(players.index[i] + ' (' + \"{:.2f}\".format(numrow[0]) + ', ' + \"{:.2f}\".format(numrow[1]) + \n",
    "              '); (' + \"{:.2f}\".format(numrow[2]) + ', ' + \"{:.2f}\".format(numrow[3]) + ')' )\n",
    "\n",
    "        row += numrow # list concat\n",
    "\n",
    "        row_df = pd.DataFrame(data = [row], columns = output.columns)\n",
    "\n",
    "        output = pd.concat([output, row_df])\n",
    "    except:\n",
    "        print(players.index[i] + ' no data')\n",
    "    \n",
    "        \n",
    "\n",
    "output = output.set_index('player')\n",
    "\n",
    "output = output.sort_values(['team', 'role', 'FV'], ascending = [True, False, False])\n",
    "#output.to_excel('outputs/pred_matchday_' + str(matchday_out) + '.xlsx')\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47cbd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "output = output.sort_values(['role', 'FV'], ascending = [False, False])\n",
    "\n",
    "template_file = 'outputs/pred_matchday_base.xlsx'\n",
    "dest_file = 'outputs/pred_avg_seriea.xlsx'\n",
    "\n",
    "shutil.copyfile(template_file, dest_file)\n",
    "\n",
    "with pd.ExcelWriter(dest_file, mode = 'a', engine=\"openpyxl\", if_sheet_exists = 'replace') as writer:  \n",
    "    output.to_excel(writer, sheet_name='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9df3bb",
   "metadata": {},
   "source": [
    "Various predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7300f3c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_player('Meret', log = 1, plot = 0)\n",
    "predict_player('Szczesny', log = 1, plot = 0)\n",
    "predict_player('Provedel', log = 1, plot = 0)\n",
    "predict_player('Maignan', log = 1, plot = 0)\n",
    "predict_player('Rui Patricio', log = 1, plot = 0)\n",
    "predict_player('Sommer', log = 1, plot = 0)\n",
    "predict_player('Milinkovic-Savic V.', log = 1, plot = 0)\n",
    "predict_player('Musso', log = 1, plot = 0)\n",
    "predict_player('Caprile', log = 1, plot = 0)\n",
    "predict_player('Silvestri', log = 1, plot = 0)\n",
    "predict_player('Terracciano', log = 1, plot = 0)\n",
    "predict_player('Skorupski', log = 1, plot = 0)\n",
    "predict_player('Falcone', log = 1, plot = 0)\n",
    "predict_player('Di Gregorio', log = 1, plot = 0)\n",
    "predict_player('Consigli', log = 1, plot = 0)\n",
    "predict_player('Radunovic', log = 1, plot = 0)\n",
    "predict_player('Montipo\\'', log = 1, plot = 0)\n",
    "predict_player('Martinez Jo.', log = 1, plot = 0)\n",
    "predict_player('Turati', log = 1, plot = 0)\n",
    "predict_player('Ochoa', log = 1, plot = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f5a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_player('Osimhen', log = 1)\n",
    "predict_player('Osimhen', log = 1, oldseason= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7ad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_player('Rafael Leao', plot = 1, log = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30744d7a",
   "metadata": {},
   "source": [
    "Tensorflow seems to have a custom definition for SinhArcsinh distribution. \n",
    "\n",
    "Here the code to generate the probability density function is reproduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec6c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom franction to calculate the probability density function\n",
    "\n",
    "def sinh_archsinh_pdf(x, mu, sigma, eps, delta):\n",
    "\n",
    "    mul = np.sinh( np.arcsinh(2) * delta)\n",
    "    \n",
    "    mul = 2 / mul\n",
    "    \n",
    "    sigma_corr = sigma * mul\n",
    "    \n",
    "    z = (x - mu) / sigma_corr\n",
    "    \n",
    "    \n",
    "    \n",
    "    S = np.sinh( -eps + (1/delta) * np.arcsinh(z))\n",
    "    \n",
    "    f = np.exp(-0.5 * S * S)\n",
    "\n",
    "    f /= np.sqrt(2 * np.pi)\n",
    "    \n",
    "    f *= 1 / ( sigma_corr * delta )\n",
    "    \n",
    "    f *= np.sqrt(1 + S * S)\n",
    "    \n",
    "    f /= np.sqrt(1 + z * z)\n",
    "    \n",
    "    return f\n",
    "    \n",
    "\n",
    "x = np.arange(start = 0, stop = 15, step = 0.001)\n",
    "\n",
    "\n",
    "plt.plot(x, sinh_archsinh_pdf(x, 5.54, 1.4, 0.8, 1.68))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605dc968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
